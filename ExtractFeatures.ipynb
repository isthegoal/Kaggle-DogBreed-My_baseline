{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocess \n",
    "\n",
    "- size: > 224 \n",
    "- normalized: mean = [0.485, 0.456, 0.406],  std = [0.229, 0.224, 0.225]\n",
    "- shape:  RGB images of shape (N x 3 x H x W)\n",
    "\n",
    "https://mxnet.incubator.apache.org/api/python/gluon/model_zoo.html#mxnet.gluon.model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_list = [                 #建立预处理图片内容列表，也就是对图片要做的事情  用于下面会被使用    我感觉这里会对图片进行处理，因为我看到下面有讲图像旋转 设置均值和方差等\n",
    "    lambda img: img.astype(\"float32\")/255,  #对图片特征进行处理并  进行归到0-1内的数值\n",
    "    mx.image.ForceResizeAug((224, 224)),  #调整大小 \n",
    "    mx.image.ColorNormalizeAug(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),  # 对图片进行均值和  方差规范化\n",
    "    lambda img: nd.transpose(img,(2,0,1))# j进行图片的 翻转，官方上这是一种图片矩阵的转变，而不是那种角度转变那种吧。\n",
    "]\n",
    "#  定义图片预处理函数，会调用上面的结构将图片变成上面的形式。进行预处理\n",
    "def image_preprocess(img):\n",
    "    for f in preprocess_list:  #这里的意思是对上面list列表中的每一个操作一个个的执行，去对图片进行处理\n",
    "        img = f(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img, label):       #指定图形的转换\n",
    "    return image_preprocess(img), label\n",
    "\n",
    "def load_data(data_dir, load_batch_size = 32, f_trans=transform):   #使用gluon方法去 生成数据    生成对序列数据加载后的形式  \n",
    "    imgs = mx.gluon.data.vision.ImageFolderDataset(data_dir, transform=transform)#用于加载文件夹结构中图像文件的数据集  会对这里面的所有图片执行transform函数\n",
    "    data = mx.gluon.data.DataLoader(imgs, load_batch_size, last_batch=\"keep\")# z这里为进行预训练提取特征做准备，指定每次提取的数量。\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(\"D:\\dog_data\\dogbreed\\\\train_gy\")   #这里会按批次加载数据进行处理   处理之后会进一步的投入网络中去\n",
    "test_data = load_data(\"D:\\dog_data\\dogbreed\\\\test_gy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Net Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.cpu()                #这里使用gluon框架会加载残差网络      使用残差网络进行模型的训练\n",
    "resnet50_v2 = mx.gluon.model_zoo.vision.resnet50_v2(pretrained=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction From Pretrained Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(net, data, ctx):    #定义提取特征的函数    我知道了 这里实际上应该有个跑网络的过程，  怪不得花了那么长时间。。从预训练模型里获得数据 \n",
    "    rst_X, rst_y = [], []                #这里有三个主体， 使用 net网络，是ctx机器，对data数据进行跑，将残差网络从头跑到尾部，从里面获得输出的特征结果\n",
    "    for X, y in tqdm(data):    #tqdm是一个定义的进度条，这里会 定义数据的批次提取特征的进度\n",
    "        Xi = net.features(X.as_in_context(ctx))\n",
    "        rst_X.append(Xi.asnumpy())\n",
    "        rst_y.append(y.asnumpy())\n",
    "    return np.concatenate(rst_X, axis=0), np.concatenate(rst_y, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 320/320 [37:48<00:00,  7.09s/it]\n"
     ]
    }
   ],
   "source": [
    "X_train_resnet50_v2, y_train = extract_features(resnet50_v2, train_data, ctx)   #调用上面的提取函数从train_data数据中提取特征  每批次算一个百分比，10000/32=320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████▏  | 301/324 [38:26<02:56,  7.66s/it]"
     ]
    }
   ],
   "source": [
    "X_test_resnet50_v2, _ = extract_features(resnet50_v2, test_data, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save features and labels for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py              #使用  h5py将预训练残杀网络的数据保存起来    将模型和 对应的训练标签单独同意保持在h5文件中去。。。   将提取的所有特征和对应标签进行保存\n",
    "with h5py.File('D:\\dog_data\\dogbreed/resnet50_v2_pretrained_Xy.h5', 'w') as f:\n",
    "    f['X_train_resnet50_v2'] = X_train_resnet50_v2\n",
    "    f['X_test_resnet50_v2'] = X_test_resnet50_v2\n",
    "    f['y_train'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
